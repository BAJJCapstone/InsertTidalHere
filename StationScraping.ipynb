{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\xa0Air Temperature', '\\xa0Relative Humidity', '\\xa0Rain Fall', '\\xa0Verified Daily Mean Water Level', '\\xa0Verified 6-Minute Water Level', '\\xa0Verified Monthly Mean Water Level', '\\xa0Water Conductivity', '\\xa0Verified High/Low Water Level', '\\xa0Wind', '\\xa0Visibility', '\\xa0Barometric Pressure', '\\xa0Verified Hourly Height Water Level', '\\xa0Preliminary 6-Minute Water Level', '\\xa0Water Temperature'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "prefix = 'https://tidesandcurrents.noaa.gov/'\n",
    "\n",
    "station_url = 'https://tidesandcurrents.noaa.gov/stations.html?type=Historic+Water+Levels'\n",
    "with urllib.request.urlopen(station_url) as url:\n",
    "    station_html = url.read()\n",
    "    \n",
    "soup = BeautifulSoup(station_html, \"html.parser\")\n",
    "\n",
    "stations = soup.find_all('div', {'class': lambda L: L and L.startswith('span4 station')})\n",
    "\n",
    "types = set()\n",
    "\n",
    "for station in stations:\n",
    "    with urllib.request.urlopen(prefix + station.a[\"href\"]) as url:\n",
    "        individual_html = url.read()\n",
    "    individual_soup = BeautifulSoup(individual_html, \"html.parser\")\n",
    "    available = individual_soup.find_all('tr')\n",
    "    for data in available[1:]:\n",
    "        types.add(data.find_all('td')[0].get_text().replace(u'\\xa0',u''))\n",
    "        \n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tidesandcurrents.noaa.gov/inventory.html?id=8730667\n"
     ]
    }
   ],
   "source": [
    "print(prefix + stations[0].a[\"href\"])\n",
    "\n",
    "with urllib.request.urlopen(prefix + stations[0].a[\"href\"]) as url:\n",
    "    individual_html = url.read()\n",
    "    \n",
    "individual_soup = BeautifulSoup(individual_html, \"html.parser\")    \n",
    "    \n",
    "# print(individual_soup.prettify()[3000:4000])\n",
    "\n",
    "tests = individual_soup.find_all('tr')#, {'class': 'legenditem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preliminary 6-Minute Water Level\n",
      "2006-10-14 22:24\n",
      "2007-03-26 19:54\n",
      " Verified Monthly Mean Water Level\n",
      "1993-12-01 00:00\n",
      "1994-03-31 23:54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for test in tests[1:]:\n",
    "    print(test.find_all('td')[0].get_text())\n",
    "    print(test.find_all('td')[1].get_text())\n",
    "    print(test.find_all('td')[2].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_info = {}\n",
    "\n",
    "station_info['ID'] = {}\n",
    "station_info['dates'] = {}\n",
    "\n",
    "for station in stations:\n",
    "    link_suffix = station.a['href']\n",
    "    key = ''.join(station.a.get_text().split()[1:])\n",
    "    station_info['dates'][key] = station.span.get_text()\n",
    "    station_info['ID'][key] = station.a.get_text().split()[0]\n",
    "    \n",
    "\n",
    "with open(\"station_info.json\", \"w\") as writeJSON:\n",
    "    json.dump(station_info, writeJSON)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
