{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_stations = pd.read_csv('coops-activecurrentstations.csv')\n",
    "historical_stations = pd.read_csv('coops-historiccurrentstations.csv')\n",
    "\n",
    "station_id_list = []\n",
    "for ID in current_stations['Station ID']:\n",
    "    station_id_list.append(ID)\n",
    "for ID in historical_stations['Station ID']:\n",
    "    station_id_list.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cb0102': [['2016-10-20 12:50:00', '', \"36° 57.564' N\", \"76° 0.768' W\"], ['2016-03-01 15:30:00', '2016-10-20 12:45:00', \"36° 57.564' N\", \"76° 0.768' W\"], ['2015-10-22 17:00:00', '2016-03-01 15:00:00', \"36° 57.564' N\", \"76° 0.768' W\"], ['2015-06-23 18:00:00', '2015-10-22 16:30:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2015-01-06 17:10:00', '2015-06-23 17:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2014-06-25 15:00:00', '2015-01-06 16:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2014-01-06 14:00:00', '2014-06-24 23:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2013-08-07 14:00:00', '2014-01-06 13:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2013-05-09 16:50:00', '2013-08-06 23:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2012-09-21 19:00:00', '2013-05-09 15:15:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2012-05-11 19:00:00', '2012-09-21 18:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2012-03-22 15:00:00', '2012-05-04 16:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2011-09-28 17:00:00', '2012-03-22 14:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2011-02-16 16:00:00', '2011-09-28 15:15:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2010-07-15 19:00:00', '2011-02-16 15:00:00', \"36° 57.553' N\", \"76° 0.781' W\"], ['2010-01-15 16:20:00', '2010-07-15 18:45:00', \"36° 57.552' N\", \"76° 0.780' W\"], ['2009-08-27 15:50:00', '2010-01-15 15:45:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2009-06-19 13:00:00', '2009-08-25 17:00:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2009-01-22 15:00:00', '2009-06-19 12:30:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2008-07-30 18:38:00', '2009-01-22 14:20:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2007-12-05 16:32:00', '2008-07-30 14:10:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2007-08-30 15:00:00', '2007-12-05 15:30:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2007-07-26 15:48:00', '2007-08-27 13:30:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2007-06-19 15:47:00', '2007-07-19 09:00:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2007-01-12 15:45:00', '2007-06-19 15:00:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2006-12-14 00:00:00', '2007-01-12 13:00:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2006-05-18 00:00:00', '2006-12-13 11:00:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2005-11-08 00:00:00', '2006-05-17 23:54:00', \"36° 57.542' N\", \"76° 0.758' W\"], ['2005-10-18 00:00:00', '2005-11-07 23:54:00', \"36° 57.550' N\", \"76° 0.767' W\"], ['2005-02-09 00:00:00', '2005-10-17 23:54:00', \"36° 57.550' N\", \"76° 0.767' W\"], ['2004-05-14 00:00:00', '2005-02-08 00:00:00', \"36° 57.550' N\", \"76° 0.767' W\"]]}\n"
     ]
    }
   ],
   "source": [
    "currentStationDict = {}\n",
    "\n",
    "for station_id in station_id_list:\n",
    "    current_prefix = \"https://tidesandcurrents.noaa.gov/cdata/StationInfo?id=\"\n",
    "\n",
    "    with urllib.request.urlopen(current_prefix + station_id) as url:\n",
    "        current_html = url.read()\n",
    "\n",
    "    soup = BeautifulSoup(current_html, \"html.parser\")\n",
    "    tables = soup.find_all('table')\n",
    "    for i, table in enumerate(tables):\n",
    "        headers = table.find_all('thead')\n",
    "        for header in headers:\n",
    "            header_titles = [th.get_text() for th in header.find_all('th')]\n",
    "            desired_titles = ['Deployed', 'Recovered', 'Latitude', 'Longitude']\n",
    "            for header_title, desired_title in zip(header_titles, desired_titles):\n",
    "                if header_title != desired_title:\n",
    "                    break\n",
    "            else:\n",
    "                currentStationDict[station_id] = []\n",
    "                for entry in table.tbody.find_all('tr'):\n",
    "                    currentStationDict[station_id].append([data.get_text() for data in entry.find_all('td')])\n",
    "    \n",
    "with open(\"current_station_info.json\", \"w\") as writeJSON:\n",
    "    json.dump(currentStationDict, writeJSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
