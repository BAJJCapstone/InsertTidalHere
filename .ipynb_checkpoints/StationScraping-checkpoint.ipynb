{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inventory.html?id=8730667\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "prefix = 'https://tidesandcurrents.noaa.gov/'\n",
    "\n",
    "station_url = 'https://tidesandcurrents.noaa.gov/stations.html?type=Historic+Water+Levels'\n",
    "with urllib.request.urlopen(station_url) as url:\n",
    "    station_html = url.read()\n",
    "    \n",
    "soup = BeautifulSoup(station_html, \"html.parser\")\n",
    "\n",
    "stations = soup.find_all('div', {'class': lambda L: L and L.startswith('span4 station')})\n",
    "\n",
    "print(stations[0].a[\"href\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tidesandcurrents.noaa.gov/inventory.html?id=8730667\n"
     ]
    }
   ],
   "source": [
    "print(prefix + stations[0].a[\"href\"])\n",
    "\n",
    "with urllib.request.urlopen(prefix + stations[0].a[\"href\"]) as url:\n",
    "    individual_html = url.read()\n",
    "    \n",
    "individual_soup = BeautifulSoup(individual_html, \"html.parser\")    \n",
    "    \n",
    "# print(individual_soup.prettify()[3000:4000])\n",
    "\n",
    "test = individual_soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_info = {}\n",
    "\n",
    "station_info['ID'] = {}\n",
    "station_info['dates'] = {}\n",
    "\n",
    "for station in stations:\n",
    "    link_suffix = station.a['href']\n",
    "    key = ''.join(station.a.get_text().split()[1:])\n",
    "    station_info['dates'][key] = station.span.get_text()\n",
    "    station_info['ID'][key] = station.a.get_text().split()[0]\n",
    "    \n",
    "\n",
    "with open(\"station_info.json\", \"w\") as writeJSON:\n",
    "    json.dump(station_info, writeJSON)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
